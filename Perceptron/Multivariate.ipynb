{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second week, we have to go with a input system and face an online on naive bayes classifier.\n",
    "In the first line there are three numbers : Number of features, Number of classes and Number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features=0\n",
    "classes=0\n",
    "samples=0\n",
    "\n",
    "def data_loader(filename,isTrainData):\n",
    "    # open data file\n",
    "    file = open(\"instructions and data/during coding/\"+filename,\"r\")\n",
    "\n",
    "\n",
    "    # initialize\n",
    "    i=0\n",
    "    global features\n",
    "    global classes\n",
    "    global samples\n",
    "\n",
    "\n",
    "    listx = []\n",
    "    listy = []\n",
    "\n",
    "    for line in file:\n",
    "        # for the first line\n",
    "        if(i==0 and isTrainData==1):\n",
    "            fields = line.split()\n",
    "\n",
    "            features = int(fields[0])\n",
    "            classes = int(fields[1])\n",
    "            samples = int(fields[2])\n",
    "        # for the rest of the line\n",
    "        else:\n",
    "            fields = line.split()\n",
    "            templist = []\n",
    "\n",
    "            for j in range(features):\n",
    "                #print(fields[j])\n",
    "                templist.append(float(fields[j]))\n",
    "\n",
    "            listx.append(templist)\n",
    "            listy.append(int(fields[features]))\n",
    "\n",
    "        i = i+1\n",
    "\n",
    "    #print(str(features)+\" \"+str(classes)+\" \"+str(samples))\n",
    "\n",
    "    # convert into numpy array\n",
    "    x = np.array(listx)\n",
    "    y = np.array(listy)\n",
    "\n",
    "    #print(x.shape, y.shape)\n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (100,)\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y =  data_loader(\"Train.txt\",1)\n",
    "print(train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (100,)\n"
     ]
    }
   ],
   "source": [
    "test_x,test_y =  data_loader(\"Test.txt\",0)\n",
    "print(test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 2\n",
      "Classes: 2\n",
      "Samples: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Features: \"+str(features)+\"\\nClasses: \"+str(classes)+\"\\nSamples: \"+str(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating prior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "pre_prob = np.zeros((1, classes))\n",
    "\n",
    "for i in range(classes):\n",
    "    total = (train_y==(i+1)).sum()\n",
    "    pre_prob[0][i] = total/(samples)\n",
    "print(pre_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate mean and deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.01143   4.057054]\n",
      " [ 7.803882 10.073138]]\n",
      "[[0.25451926 0.25819941]\n",
      " [0.17793744 0.19076063]]\n",
      "[[[ 6.3629815  -0.82428432]\n",
      "  [-0.82428432  6.45498514]]\n",
      "\n",
      " [[ 4.44843596  0.37718217]\n",
      "  [ 0.37718217  4.76901583]]]\n"
     ]
    }
   ],
   "source": [
    "mean = np.zeros((classes,features))\n",
    "deviation = np.zeros((classes,features))\n",
    "covariance = np.zeros((classes,features,features))\n",
    "\n",
    "for i in range(features):\n",
    "    for j in range(classes):\n",
    "        value = 0.0\n",
    "        for k in range(samples):\n",
    "            if(train_y[k]==(j+1)):\n",
    "                value =  value + train_x[k][i]\n",
    "        mean[j][i]=value/(train_y==(j+1)).sum()\n",
    "print(mean)\n",
    "for i in range(features):\n",
    "    for j in range(classes):\n",
    "        value = 0.0\n",
    "        for k in range(samples):\n",
    "            if(train_y[k]==(j+1)):\n",
    "                value = value+ (train_x[k][i] - mean[j][i])*(train_x[k][i] - mean[j][i])\n",
    "        deviation[j][i]=value/(train_y==(j+1)).sum()\n",
    "print(deviation)\n",
    "\n",
    "for x in range(classes):\n",
    "    for i in range(features):\n",
    "        for j in range(features):\n",
    "            value = 0.0\n",
    "            for k in range(samples):\n",
    "                if(train_y[k]==(x+1)):\n",
    "                    value = value+ (train_x[k][i] - mean[x][i])*(train_x[k][j] - mean[x][j])\n",
    "            covariance[x][i][j]=value/(features)\n",
    "print(covariance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caluculate gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(value,class_no):\n",
    "    global mean\n",
    "    global covariance\n",
    "    value_min = np.zeros((features,1))\n",
    "    for i in range(features):\n",
    "        value_min[i][0] = (value[i]-mean[i][class_no])\n",
    "    \n",
    "    value_min_trans = value_min.transpose()\n",
    "    \n",
    "    covar = np.dot(value_min,value_min_trans)\n",
    "    #print(covariance.shape)\n",
    "    \n",
    "    det = np.linalg.det(covariance[class_no])\n",
    "    #print(covariance)\n",
    "    inverse = np.linalg.inv(covar)\n",
    "    p = np.dot(inverse,value_min)\n",
    "    \n",
    "    expo = np.dot(value_min_trans,p)\n",
    "    \n",
    "    expo_val = expo[0][0]*-.5\n",
    "    \n",
    "    expo_val = math.exp(expo_val)\n",
    "    #print(expo_val)\n",
    "    co_eff = expo_val/(((2*3.14159)**(features/2.0))* (abs(det)**0.5))\n",
    "    print(co_eff)\n",
    "    return co_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006211216604706723\n",
      "0.036592438097502754\n",
      "0.025041752638635853\n",
      "0.01269822836230842\n",
      "0.025041752638635853\n",
      "0.034670774883363356\n",
      "0.013935848338515574\n",
      "2.7117017468630978e-06\n",
      "0.07230002951094933\n",
      "2.2577992929197598e-08\n",
      "0.025041752638635853\n",
      "0.034670774883363356\n",
      "0.005289927482362774\n",
      "0.023903824921826793\n",
      "0.014229564216287571\n",
      "0.014835416957776555\n",
      "0.014502470835213622\n",
      "0.01573844168671568\n",
      "0.01400265265939677\n",
      "0.01879392369166502\n",
      "0.020135894880390984\n",
      "0.009039194890954472\n",
      "0.004973150473349164\n",
      "0.020743119673740148\n",
      "0.42473461446858224\n",
      "0.034670774883363356\n",
      "0.01292049147301759\n",
      "0.017657210638357127\n",
      "0.013365603947888435\n",
      "0.023164906548737884\n",
      "0.0026695142775389133\n",
      "0.034670774883363356\n",
      "0.2134717568152068\n",
      "0.034670774883363356\n",
      "0.007534590900238302\n",
      "0.02293727885806019\n",
      "0.00671325907565678\n",
      "0.06816018588496209\n",
      "0.0103512189667137\n",
      "0.0242923985540361\n",
      "0.023790272706888334\n",
      "0.007914162371142733\n",
      "0.017162118417406728\n",
      "0.026690037266909633\n",
      "0.025041752638635853\n",
      "0.036550285036543395\n",
      "0.010870245514821951\n",
      "0.019007499459851772\n",
      "0.025041752638635853\n",
      "0.002210332838183791\n",
      "0.011474177058479078\n",
      "0.0597632910067798\n",
      "0.0002502298301936569\n",
      "0.022341783161981325\n",
      "0.025041752638635853\n",
      "0.015449356619143982\n",
      "0.025041752638635853\n",
      "0.024284201252896494\n",
      "0.012885202208905194\n",
      "0.034670774883363356\n",
      "0.006717422586838916\n",
      "0.0068591780014919225\n",
      "0.01597323545222724\n",
      "1.6042179651100995e-06\n",
      "0.07932747496821342\n",
      "0.023779699028912162\n",
      "0.017936272109270825\n",
      "0.034670774883363356\n",
      "317.75138167104063\n",
      "0.034670774883363356\n",
      "0.00389286557200858\n",
      "0.021908563980112834\n",
      "0.01615386415056988\n",
      "0.056271354787325915\n",
      "0.025041752638635853\n",
      "0.034670774883363356\n",
      "0.010500307446335682\n",
      "1.3384115249966546e-07\n",
      "0.01697445449835648\n",
      "5.361875677258882e-11\n",
      "0.0061283101146733\n",
      "0.034670774883363356\n",
      "0.03687985759368067\n",
      "0.020663804806903236\n",
      "0.0539578149879277\n",
      "0.01715239792783295\n",
      "0.025041752638635853\n",
      "0.006451051299541119\n",
      "0.025041752638635853\n",
      "0.03837454540459327\n",
      "0.06702495664932874\n",
      "0.7724490946464605\n",
      "0.019333015601502277\n",
      "0.019331455922435025\n",
      "0.003977897993081671\n",
      "0.034670774883363356\n",
      "0.056091163532817526\n",
      "0.034670774883363356\n",
      "0.025041752638635853\n",
      "0.010394071647300544\n",
      "0.01457961816584722\n",
      "0.015303428062940114\n",
      "0.025041752638635853\n",
      "0.02057099830767493\n",
      "0.01948340665097381\n",
      "0.01254109196174579\n",
      "0.05417344194484268\n",
      "0.01618883585154935\n",
      "0.011713866223025502\n",
      "0.012651308008414795\n",
      "0.010079821330508918\n",
      "0.004873069907786825\n",
      "0.0130944147893887\n",
      "0.034670774883363356\n",
      "0.013525398487611773\n",
      "0.034670774883363356\n",
      "0.009722915648583295\n",
      "0.02377796020199726\n",
      "0.011491967204420426\n",
      "0.010620433770959873\n",
      "0.0064132668323417415\n",
      "0.012004848498211342\n",
      "0.025041752638635853\n",
      "0.013077727726246817\n",
      "0.025041752638635853\n",
      "0.034670774883363356\n",
      "0.0013635062912508303\n",
      "0.01976279460508854\n",
      "0.025041752638635853\n",
      "0.034670774883363356\n",
      "0.025041752638635853\n",
      "0.022557736963638275\n",
      "0.025041752638635853\n",
      "0.01361585754840763\n",
      "0.006802864594267416\n",
      "0.006047766980042061\n",
      "0.01700658356026678\n",
      "0.0313329923063515\n",
      "0.01753747749781705\n",
      "0.034670774883363356\n",
      "0.025041752638635853\n",
      "0.022535979247255887\n",
      "0.025041752638635853\n",
      "0.00014155047803313952\n",
      "0.01850737474172105\n",
      "1.2532940130698467e-05\n",
      "0.019591955285000913\n",
      "0.018490599812455648\n",
      "0.013174534837311375\n",
      "0.00043505931959862763\n",
      "0.025041752638635853\n",
      "0.00027992239070210803\n",
      "0.025041752638635853\n",
      "0.021933652685861216\n",
      "0.029730398394426875\n",
      "0.009584314536033287\n",
      "0.025041752638635853\n",
      "0.0005418051249288387\n",
      "0.025041752638635853\n",
      "0.005394468677970845\n",
      "0.08487771192343645\n",
      "0.02127981795525974\n",
      "0.007309943446963109\n",
      "0.018589585131031747\n",
      "0.011901184254349526\n",
      "0.019923827149924033\n",
      "0.01649430281492232\n",
      "0.019044133658317672\n",
      "0.011255403082302159\n",
      "0.10291296280660846\n",
      "0.0028372252142869012\n",
      "0.011850388000493827\n",
      "0.025041752638635853\n",
      "0.0594832112995192\n",
      "0.014967632515659737\n",
      "0.013997137713861468\n",
      "0.021538685897825326\n",
      "0.07538935688677956\n",
      "0.026704168113390936\n",
      "0.016371178163789416\n",
      "0.007400344382761018\n",
      "0.020507242361959447\n",
      "0.009226781495617694\n",
      "0.034670774883363356\n",
      "0.0016194061975663143\n",
      "0.006235283889571831\n",
      "0.025041752638635853\n",
      "0.034670774883363356\n",
      "0.0062701876807963585\n",
      "0.01490408907258439\n",
      "0.012383912946864495\n",
      "0.034670774883363356\n",
      "0.019613559972065417\n",
      "0.019951974476722326\n",
      "0.12785055430779108\n",
      "0.034499224989163205\n",
      "0.012360405851078168\n",
      "0.04363770672318193\n",
      "0.0019303658361015002\n",
      "0.16172867892539453\n"
     ]
    }
   ],
   "source": [
    "predict = np.zeros((samples,1))\n",
    "for i in range(samples):\n",
    "    \n",
    "    prob_list = []\n",
    "    for j in range(classes):\n",
    "        value =  gauss(test_x[i],j)\n",
    "        prob_list.append(value*pre_prob[0][j])\n",
    "    pos = prob_list.index(max(prob_list))\n",
    "    predict[i] = pos+1\n",
    "#print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.46613.9251 1 2\n",
      "3 1.25074.1563 1 2\n",
      "6 2.04173.2886 1 2\n",
      "7 2.78884.1234 1 2\n",
      "8 1.83463.2821 1 2\n",
      "9 2.39764.0743 1 2\n",
      "10 1.60763.1535 1 2\n",
      "12 2.33334.5709 1 2\n",
      "14 1.34974.6918 1 2\n",
      "15 1.69753.621 1 2\n",
      "16 1.25574.2213 1 2\n",
      "18 1.86133.463 1 2\n",
      "19 1.35324.1009 1 2\n",
      "20 1.55584.3814 1 2\n",
      "22 1.96423.5235 1 2\n",
      "23 0.79274.3891 1 2\n",
      "24 1.65283.9968 1 2\n",
      "26 2.16484.6821 1 2\n",
      "27 2.29934.241 1 2\n",
      "30 0.68253.9166 1 2\n",
      "31 2.0143.5919 1 2\n",
      "34 1.83623.5314 1 2\n",
      "36 2.294.841 1 2\n",
      "37 2.11994.2968 1 2\n",
      "38 1.82464.3951 1 2\n",
      "41 1.44594.4355 1 2\n",
      "45 2.25013.6573 1 2\n",
      "46 1.74143.8658 1 2\n",
      "48 1.62334.1243 1 2\n",
      "52 1.74461.7209 2 1\n",
      "53 8.124610.3361 2 1\n",
      "54 8.184610.0693 2 1\n",
      "56 7.98149.6239 2 1\n",
      "60 8.242610.4031 2 1\n",
      "62 7.9579.8133 2 1\n",
      "66 7.80889.2135 2 1\n",
      "67 7.523311.0078 2 1\n",
      "68 8.11689.964 2 1\n",
      "71 7.749210.0866 2 1\n",
      "72 8.361410.4616 2 1\n",
      "73 8.01979.9107 2 1\n",
      "74 8.77069.7391 2 1\n",
      "75 7.149510.716 2 1\n",
      "76 7.48319.5649 2 1\n",
      "77 7.618110.4038 2 1\n",
      "78 9.08829.7447 2 1\n",
      "79 8.215810.3718 2 1\n",
      "80 7.778110.4239 2 1\n",
      "81 8.0159.585 2 1\n",
      "88 7.94329.8625 2 1\n",
      "90 7.60039.4582 2 1\n",
      "98 8.532710.0555 2 1\n",
      "Accuracy : 48.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(samples):\n",
    "    if test_y[i] == int(predict[i][0]):\n",
    "        correct = correct+1\n",
    "    else:\n",
    "        feature_str=\"\"\n",
    "        for j in range(features):\n",
    "            feature_str = feature_str +str(test_x[i][j])\n",
    "        print(str(i+1)+\" \"+feature_str +\" \"+str(test_y[i])+\" \"+str(int(predict[i][0])))\n",
    "print(\"Accuracy : \" +str((correct*100)/samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
