{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the fourth week, we have to go with a input system and face an online on linear classifier.\n",
    "In the first line there are three numbers : Number of features, Number of classes and Number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features=0\n",
    "classes=0\n",
    "samples=0\n",
    "\n",
    "def data_loader(filename,isTrainData):\n",
    "    # open data file\n",
    "    file = open(\"Data_files/Lab#2/\"+filename,\"r\")\n",
    "\n",
    "\n",
    "    # initialize\n",
    "    i=0\n",
    "    global features\n",
    "    global classes\n",
    "    global samples\n",
    "\n",
    "\n",
    "    listx = []\n",
    "    listy = []\n",
    "\n",
    "    for line in file:\n",
    "        # for the first line\n",
    "        if(i==0 and isTrainData==1):\n",
    "            fields = line.split()\n",
    "\n",
    "            features = int(fields[0])\n",
    "            classes = int(fields[1])\n",
    "            samples = int(fields[2])\n",
    "        # for the rest of the line\n",
    "        else:\n",
    "            fields = line.split()\n",
    "            templist = []\n",
    "\n",
    "            for j in range(features):\n",
    "                #print(fields[j])\n",
    "                templist.append(float(fields[j]))\n",
    "\n",
    "            listx.append(templist)\n",
    "            listy.append(int(fields[features]))\n",
    "\n",
    "        i = i+1\n",
    "\n",
    "    #print(str(features)+\" \"+str(classes)+\" \"+str(samples))\n",
    "\n",
    "    # convert into numpy array\n",
    "    x = np.array(listx)\n",
    "    y = np.array(listy)\n",
    "\n",
    "    #print(x.shape, y.shape)\n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(400, 4) (400,)\n"
    }
   ],
   "source": [
    "train_x,train_y =  data_loader(\"trainLinearlySeparable.txt\",1)\n",
    "print(train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(400, 4) (400,)\n"
    }
   ],
   "source": [
    "test_x,test_y =  data_loader(\"testLinearlySeparable.txt\",0)\n",
    "print(test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take random weights and bias and train data by basic parceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.54340494 0.27836939 0.42451759 0.84477613]\n[0.00471886]\n4\n[ 7.01448361  4.54982308 -0.01094523 -9.17600987]\n[68.60471886]\n"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "w = np.random.rand(features)\n",
    "print(w)\n",
    "bias = np.random.rand(1)\n",
    "print(bias)\n",
    "\n",
    "iteration = 0\n",
    "max_iteration = 500\n",
    "learning_rate = 0.7\n",
    "#loss_rate = []\n",
    "unchanged = 0\n",
    "while True :\n",
    "    if iteration>=max_iteration :\n",
    "        break\n",
    "    iteration = iteration + 1\n",
    "    for i in range(samples):\n",
    "        value = bias[0]\n",
    "        for j in range(features):\n",
    "            value = value + w[j]*train_x[i][j]\n",
    "            \n",
    "        choosedclass = -1\n",
    "        if value>=0:\n",
    "            choosedclass = 1\n",
    "        else :\n",
    "            choosedclass = 2\n",
    "            \n",
    "        if choosedclass == train_y[i]:\n",
    "            unchanged = unchanged +1\n",
    "        else:\n",
    "            unchanged = 0\n",
    "            for j in range(features):\n",
    "                if choosedclass == 1:\n",
    "                    w[j] = w[j]-learning_rate*1*train_x[i][j]\n",
    "                else:\n",
    "                    w[j] = w[j]-learning_rate*-1*train_x[i][j]\n",
    "            if choosedclass == 1:\n",
    "                bias[0] = bias[0]-learning_rate*1*1\n",
    "            else:\n",
    "                bias[0] = bias[0]-learning_rate*-1*1\n",
    "        if unchanged == samples:\n",
    "            break\n",
    "    if unchanged == samples:\n",
    "        break\n",
    "\n",
    "\n",
    "print(iteration)\n",
    "print(w)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find accuracy from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test sample no #2 : [ 4.17769526  7.4895456  11.37793957 15.57639853]\nTest sample no #5 : [2.15926658 3.95769032 6.83798977 7.72744903]\nTest sample no #6 : [2.72204167 4.2235373  6.26819707 7.82572434]\nTest sample no #7 : [ 4.59205674  8.10291747 12.06621406 15.73855582]\nTest sample no #8 : [ 4.46991307  7.31892588 11.60406706 16.33148364]\nTest sample no #10 : [ 5.82175777  7.61577257 11.89427062 15.62478438]\nTest sample no #12 : [1.70835485 4.76475455 5.77305841 8.28533525]\nTest sample no #14 : [2.28324796 4.11304961 7.16974307 8.29257541]\nTest sample no #16 : [ 3.72734941  7.89998318 11.54047801 15.79334979]\nTest sample no #17 : [2.08223937 3.68114905 5.71082204 7.47119784]\nTest sample no #18 : [2.18639544 3.89927728 5.27232602 8.23518741]\nTest sample no #20 : [ 2.52413831  8.0822256  12.34608714 16.63399559]\nTest sample no #21 : [ 4.90088805  7.59674861 11.31106037 15.66131842]\nTest sample no #23 : [ 4.42461508  7.86951284 11.43739626 16.18947979]\nTest sample no #24 : [ 3.78158717  8.22874083 11.57482201 16.55757911]\nTest sample no #25 : [1.59151848 4.05791402 5.7177176  8.42003141]\nTest sample no #26 : [ 3.78127072  8.66761603 11.4751791  16.6777554 ]\nTest sample no #29 : [1.67562535 3.91106325 6.55170373 8.02235837]\nTest sample no #30 : [ 4.43369863  7.80187413 11.73043653 16.65910854]\nTest sample no #31 : [ 3.74044065  7.99639282 12.23817158 15.84290475]\nTest sample no #35 : [2.80533645 4.52864149 6.04294719 7.56992537]\nTest sample no #36 : [ 4.50520379  8.12706104 12.54627281 15.98619372]\nTest sample no #37 : [1.79975441 4.13748596 5.85628515 9.07599244]\nTest sample no #38 : [ 3.89846513  7.74876563 11.40002164 16.04293363]\nTest sample no #39 : [ 3.13531233  8.74323143 12.55748291 15.94117551]\nTest sample no #40 : [ 3.50358235  8.63887174 11.58938819 16.05551001]\nTest sample no #41 : [2.10176161 3.69974769 5.76885839 8.4169112 ]\nTest sample no #42 : [2.11565128 4.5948293  6.15622424 7.08002561]\nTest sample no #45 : [2.1957059  3.7756148  5.61044541 7.33702362]\nTest sample no #51 : [ 3.94575517  7.46047678 12.24916388 16.12356001]\nTest sample no #52 : [2.07170389 4.08329001 5.94293974 7.90625895]\nTest sample no #53 : [1.67422516 4.83359805 6.64547876 8.6833508 ]\nTest sample no #54 : [2.21796924 3.51333773 5.72125964 7.95240322]\nTest sample no #55 : [ 4.08286929  8.17344138 11.59959759 16.15476262]\nTest sample no #56 : [ 3.68467714  7.87042894 12.53216257 16.23519021]\nTest sample no #59 : [ 4.87071279  8.36083318 11.16469138 16.24238583]\nTest sample no #61 : [ 4.42661677  9.54664267 11.84823041 16.2917978 ]\nTest sample no #66 : [1.22753673 4.19261261 5.50070159 7.62718082]\nTest sample no #68 : [ 3.28962905  7.83150622 11.2943444  16.95354721]\nTest sample no #70 : [ 4.53912421  8.12507787 12.29307145 15.96411918]\nTest sample no #73 : [1.80309206 4.67411925 6.05118883 8.78569743]\nTest sample no #74 : [1.8814488  3.82001848 6.32772477 8.48082712]\nTest sample no #75 : [ 3.8343591   8.58145606 12.01237789 15.88330849]\nTest sample no #76 : [1.78643226 4.43717288 6.57863718 8.5418388 ]\nTest sample no #78 : [ 3.6438199   7.50405715 12.60524257 16.60985511]\nTest sample no #79 : [1.99526154 3.85381854 6.29975262 7.70209002]\nTest sample no #82 : [ 3.82335252  7.16836807 11.88859506 15.48307897]\nTest sample no #83 : [2.02951533 4.08247095 6.24760252 8.93850645]\nTest sample no #85 : [1.89670442 3.56012402 6.82223183 7.97521644]\nTest sample no #86 : [ 3.86812296  7.87630289 11.65034256 16.00582459]\nTest sample no #87 : [1.39660104 3.45625757 5.64843146 8.38762853]\nTest sample no #90 : [ 3.98958211  8.21816952 12.86774157 16.29233058]\nTest sample no #92 : [ 5.21546583  7.92574074 12.78760408 16.91913607]\nTest sample no #93 : [ 4.34562554  8.41752551 13.16995157 16.25329865]\nTest sample no #96 : [1.57867286 3.59989045 5.98002596 8.70424971]\nTest sample no #98 : [ 3.35076712  7.74418301 11.64312963 16.39511751]\nTest sample no #99 : [2.1236681  4.56952188 5.55893566 8.02441507]\nTest sample no #106 : [2.15143787 3.51056577 5.96270651 8.63676134]\nTest sample no #107 : [1.50130902 4.20752193 6.3144858  8.11684913]\nTest sample no #108 : [1.44090111 4.1270387  6.30147205 8.39963865]\nTest sample no #112 : [ 4.42689991  7.36431955 12.03594634 16.38656357]\nTest sample no #113 : [1.56335059 2.84128806 6.42108856 6.98105923]\nTest sample no #114 : [ 4.39659622  7.65185084 11.92289605 15.57507323]\nTest sample no #115 : [2.53519774 3.26847299 5.95545229 9.37400071]\nTest sample no #116 : [1.76073324 3.79868971 6.77560357 8.83926205]\nTest sample no #119 : [2.18405357 4.16708897 7.02182619 7.72913837]\nTest sample no #124 : [2.26835932 3.69888165 6.35340341 8.7859507 ]\nTest sample no #125 : [ 4.92250757  7.49471084 11.30621843 15.75050815]\nTest sample no #126 : [ 3.68597325  7.62924518 11.57452909 15.72891618]\nTest sample no #128 : [ 4.39236116  8.28456088 12.04942462 15.77854711]\nTest sample no #132 : [1.08136787 3.93069143 6.10778322 7.60022031]\nTest sample no #133 : [1.37108418 4.05515584 6.94730524 7.73920201]\nTest sample no #138 : [ 2.97439207  9.08424355 11.67039337 15.43029376]\nTest sample no #140 : [ 3.97595549  7.62294871 11.95394728 15.98262983]\nTest sample no #141 : [ 4.03008943  8.42743791 11.70143678 16.55066156]\nTest sample no #142 : [2.0749265  3.32305938 6.31662859 8.4724493 ]\nTest sample no #144 : [ 3.99171702  7.6789645  11.41024739 15.93128586]\nTest sample no #145 : [1.15048179 3.78872106 5.98918176 7.92776958]\nTest sample no #147 : [ 4.80163673  6.92897759 11.52580842 16.10830634]\nTest sample no #153 : [2.10972568 3.02162762 6.60231089 7.55175958]\nTest sample no #154 : [ 4.2051264   8.27334422 12.10171027 16.36403407]\nTest sample no #155 : [ 4.06300134  8.24098639 11.59896936 15.39175566]\nTest sample no #156 : [ 3.76855094  7.51079708 12.21861607 15.82932249]\nTest sample no #158 : [1.91330633 3.73586547 5.17763713 7.96548069]\nTest sample no #160 : [1.43439733 4.23264506 5.88409202 8.68473341]\nTest sample no #161 : [2.46752096 3.9478532  5.15304917 8.12325776]\nTest sample no #162 : [ 3.65940237  7.78142656 11.71404739 15.54342186]\nTest sample no #166 : [1.98817884 3.71608009 6.33213575 8.06147862]\nTest sample no #167 : [ 4.40459117  7.89569009 12.37480094 16.36052904]\nTest sample no #168 : [1.87499645 3.34463275 6.22379073 7.96485828]\nTest sample no #169 : [ 4.59497919  7.8728591  12.19422082 15.96893232]\nTest sample no #170 : [ 3.7100143   7.98787994 12.22977744 15.86509179]\nTest sample no #171 : [1.73839772 4.32521918 5.54752565 7.31025199]\nTest sample no #173 : [ 4.27752148  7.70488431 12.2176042  15.32294826]\nTest sample no #175 : [0.85080722 4.36220869 5.12819631 7.9849732 ]\nTest sample no #177 : [ 4.50756408  7.78405115 11.63855098 15.86061619]\nTest sample no #178 : [1.52068512 4.254039   5.82053827 6.76263442]\nTest sample no #179 : [2.68139097 4.09295136 6.4285568  7.86790377]\nTest sample no #180 : [1.73660497 3.71007215 4.80074793 8.2794755 ]\nTest sample no #181 : [3.19603004 4.04766508 6.28695736 8.58993723]\nTest sample no #184 : [2.43951396 4.57244525 6.05912907 8.28987408]\nTest sample no #185 : [1.17355576 4.29952489 5.21743196 8.14931403]\nTest sample no #188 : [ 3.39369755  7.54786856 12.01680465 15.05625069]\nTest sample no #192 : [ 3.67826946  8.84210784 11.35266989 16.23547323]\nTest sample no #193 : [1.77669453 3.53556441 6.08976704 7.28770907]\nTest sample no #194 : [ 3.62218219  8.8030931  11.7454117  15.77349953]\nTest sample no #195 : [ 3.72293911  8.66611993 13.03252222 15.44983595]\nTest sample no #196 : [1.72756317 5.15477975 5.8323086  7.09189777]\nTest sample no #197 : [2.1796764  3.54821478 4.94888607 8.06526022]\nTest sample no #198 : [2.26436756 3.48602881 5.12233884 6.95161412]\nTest sample no #199 : [2.65994013 4.31656586 6.48712127 7.46628655]\nTest sample no #200 : [ 4.37050459  7.41915364 11.47822681 15.84282645]\nTest sample no #201 : [1.95731228 3.47041344 6.22425846 8.01739178]\nTest sample no #203 : [ 4.07472919  7.63111697 11.53832032 15.08950592]\nTest sample no #206 : [2.47614004 3.89747284 5.90700813 8.13018904]\nTest sample no #207 : [ 4.17607589  6.27796504 11.08111621 16.00119373]\nTest sample no #210 : [1.89464643 3.77031797 6.1740947  8.16727171]\nTest sample no #211 : [ 3.49036183  9.41196773 11.9075624  15.74828845]\nTest sample no #214 : [1.36615451 3.14189385 6.4028176  8.63135995]\nTest sample no #216 : [2.44855245 4.97134069 6.07366177 8.0853005 ]\nTest sample no #217 : [ 4.58044049  8.23980212 11.77930108 15.68889117]\nTest sample no #220 : [2.270205   3.4825682  7.33443781 8.2412903 ]\nTest sample no #223 : [1.93562647 4.20142099 5.397303   8.64699478]\nTest sample no #224 : [ 4.16079349  8.61740922 11.79665916 16.48551339]\nTest sample no #225 : [2.01910018 4.63142298 6.23611511 8.32595867]\nTest sample no #226 : [2.71454747 3.91410812 6.22599773 7.68811462]\nTest sample no #231 : [1.20706501 3.9215895  6.94761652 8.56843523]\nTest sample no #235 : [ 4.32056062  7.30758245 12.01105886 15.74880018]\nTest sample no #239 : [ 3.78702485  8.66641592 11.2574034  16.3156045 ]\nTest sample no #240 : [1.96501882 3.63869534 5.56378316 8.03821497]\nTest sample no #242 : [ 4.04751539  8.76014366 12.26430758 16.21025562]\nTest sample no #244 : [ 3.76288789  6.86676565 12.26477085 15.80468081]\nTest sample no #245 : [0.44711366 3.61584081 6.70329773 9.0538061 ]\nTest sample no #249 : [ 4.03331688  8.55012342 13.12511642 16.25423079]\nTest sample no #250 : [ 3.60209018  8.01232944 12.26116672 15.46504612]\nTest sample no #251 : [2.07573946 3.71426657 5.82018864 8.04174795]\nTest sample no #256 : [2.82781318 3.48459539 5.34687042 7.42430771]\nTest sample no #257 : [ 4.34483728  7.56101955 12.37373337 16.05185113]\nTest sample no #258 : [ 3.59812132  8.36875326 12.49824137 16.6854591 ]\nTest sample no #259 : [1.0956279  3.60484267 6.04711477 7.39203172]\nTest sample no #260 : [ 4.63073053  7.95794254 11.75424022 16.05598189]\nTest sample no #264 : [2.36660116 4.35061241 5.81363978 8.16521347]\nTest sample no #266 : [ 4.11416985  8.2474618  11.65422725 15.25693767]\nTest sample no #268 : [ 4.57214649  7.73551179 11.52143554 15.71819438]\nTest sample no #271 : [ 4.5376371   8.57817106 11.31859631 15.52516714]\nTest sample no #272 : [2.58079729 4.46163768 5.20070345 7.09874126]\nTest sample no #274 : [2.51210969 4.70859604 4.93079582 8.69393676]\nTest sample no #275 : [2.00872432 3.56988028 6.14309673 8.23153548]\nTest sample no #277 : [ 4.54273612  8.06082875 12.8616882  16.22641339]\nTest sample no #278 : [ 3.67665337  8.21053494 11.76397372 16.06247741]\nTest sample no #286 : [2.01733003 3.91588366 6.65523666 7.71519382]\nTest sample no #288 : [1.563678   3.63754581 6.13331882 8.41465798]\nTest sample no #289 : [ 3.39363995  8.29187765 11.82806395 16.38779347]\nTest sample no #292 : [2.29412604 4.03737233 5.14636653 8.11931321]\nTest sample no #294 : [ 3.87038333  7.10178415 12.01075823 16.70745779]\nTest sample no #295 : [2.29926086 3.57801342 6.29239867 6.66683887]\nTest sample no #304 : [ 3.8277901   8.21029634 12.07564578 15.49524875]\nTest sample no #305 : [ 3.65091664  8.28959103 12.97027261 16.5443869 ]\nTest sample no #306 : [1.69646617 3.99361259 6.23998264 7.44852096]\nTest sample no #308 : [2.366416   3.69635886 5.92721943 7.74087831]\nTest sample no #310 : [ 3.20089307  7.24080347 11.22662387 16.05693192]\nTest sample no #311 : [1.65158028 3.41122768 6.14693544 7.52167621]\nTest sample no #312 : [ 3.59955942  8.00095825 12.06216298 15.64174887]\nTest sample no #314 : [2.00750015 3.61094198 6.39604178 8.0937127 ]\nTest sample no #315 : [2.62382325 4.54637058 6.51590135 8.41165445]\nTest sample no #316 : [ 3.24161198  7.79144226 11.75646857 16.46102251]\nTest sample no #318 : [ 3.81262178  7.36197947 12.37827108 15.8270023 ]\nTest sample no #319 : [1.68280598 3.83962765 5.72375282 7.93795   ]\nTest sample no #320 : [ 3.9250057   8.9543758  12.63352333 15.94430263]\nTest sample no #321 : [1.96284995 3.81032008 5.99343953 8.57848826]\nTest sample no #323 : [2.54010847 4.55532111 6.35675495 7.67693178]\nTest sample no #329 : [ 4.42695536  8.68119234 12.53829215 15.51222249]\nTest sample no #330 : [2.2767175  3.97789745 5.9070313  8.48245293]\nTest sample no #331 : [ 4.00760371  8.22814388 12.43377879 16.18539997]\nTest sample no #332 : [ 3.29017904  8.41232112 11.74079181 15.87743765]\nTest sample no #333 : [2.27232888 3.45529776 5.52380011 8.21588802]\nTest sample no #334 : [2.13020775 3.47606927 6.56000012 8.16670687]\nTest sample no #335 : [ 4.43231802  8.15490593 12.22709429 16.03376819]\nTest sample no #336 : [ 3.58598529  8.40848897 12.99145821 15.96615815]\nTest sample no #337 : [ 4.40033405  7.39579185 11.98655105 16.3422288 ]\nTest sample no #339 : [2.34571915 3.69126647 5.05069961 7.84062686]\nTest sample no #340 : [2.09847056 4.84657851 6.1489847  7.460029  ]\nTest sample no #343 : [2.41380165 4.16612631 6.49573307 8.21254958]\nTest sample no #346 : [1.24790894 4.34825829 5.82281681 8.6217681 ]\nTest sample no #351 : [2.14855108 4.25133431 6.33068204 7.88188012]\nTest sample no #352 : [ 4.18380906  7.89818707 12.21151721 15.93520789]\nTest sample no #354 : [2.17419335 3.39330983 6.06668462 8.19112771]\nTest sample no #355 : [ 4.34733306  7.66395505 11.59209082 16.3878777 ]\nTest sample no #356 : [1.45352499 3.92326619 6.13878369 8.4653081 ]\nTest sample no #359 : [ 4.6659024   7.35763815 12.83119628 15.53327962]\nTest sample no #360 : [ 3.9894759   8.08325171 12.78744562 16.22993902]\nTest sample no #363 : [2.24900037 2.91950215 5.99236435 8.19311857]\nTest sample no #364 : [1.47531637 3.63217439 5.59402086 7.02229706]\nTest sample no #365 : [ 3.94478263  8.62460166 11.78017025 15.80551182]\nTest sample no #370 : [1.90110888 4.05971956 6.12157133 7.10844642]\nTest sample no #372 : [2.42078019 4.8252474  5.37790572 7.97665182]\nTest sample no #374 : [ 4.32758635  8.59985574 11.1768833  16.10881226]\nTest sample no #377 : [ 4.54778703  8.16930679 11.46193868 16.02242224]\nTest sample no #378 : [2.68645911 2.98253581 5.88420018 8.08060427]\nTest sample no #380 : [ 4.02222105  8.60319886 11.53832463 16.04122336]\nTest sample no #383 : [1.98400729 4.11182993 5.39795611 7.88446   ]\nTest sample no #387 : [ 3.87673304  7.26158787 11.58420895 15.52180436]\nTest sample no #392 : [1.76151582 4.38630141 5.93445651 7.88958212]\nTest sample no #393 : [ 3.40785446  7.15934388 12.44531804 15.64065291]\nTest sample no #396 : [ 3.12678552  8.03724547 12.05360897 15.15097803]\nTest sample no #397 : [1.44110731 3.8250473  5.91861302 8.99984077]\nTest sample no #398 : [ 4.36533515  8.9756975  11.29523632 15.91063316]\nTest sample no #399 : [ 3.43143707  7.93925726 11.62692434 15.91871883]\nAccuracy : 48.0\n"
    }
   ],
   "source": [
    "correct = 0\n",
    "current_pred  = test_y.copy()\n",
    "for i in range(samples):\n",
    "    value = bias[0];\n",
    "    for j in range(features):\n",
    "        value = value + w[j]*test_x[i][j]\n",
    "    if value>=0:\n",
    "        current_pred[i] = 1\n",
    "    else :\n",
    "        current_pred[i] = 2\n",
    "for i in range(samples):\n",
    "    if current_pred[i] == train_y[i]:\n",
    "        correct = correct + 1\n",
    "    else:\n",
    "        print(\"Test sample no #\"+str(i+1)+\" : \"+str(test_x[i]))\n",
    "\n",
    "print(\"Accuracy : \"+str((correct/samples)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}