{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit ('deep-learning': conda)",
   "display_name": "Python 3.7.3 64-bit ('deep-learning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4efef21ae8d3e526766593316eddf58c065dc2704451dcdc2461b441e246bb8c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features=0\n",
    "classes=0\n",
    "samples=0\n",
    "def modify_y(classes,y):\n",
    "    encoder = OneHotEncoder(sparse = False)\n",
    "    encoded_y= encoder.fit_transform(y.reshape(-1, 1))\n",
    "    return encoded_y\n",
    "\n",
    "\n",
    "def data_loader(filename,isTrainData):\n",
    "    # open data file\n",
    "    file = open('./Dataset/'+filename,\"r\")\n",
    "\n",
    "\n",
    "    # initialize\n",
    "    i=0\n",
    "    global features\n",
    "    global classes\n",
    "    global samples\n",
    "\n",
    "\n",
    "    listx = []\n",
    "    listy = []\n",
    "\n",
    "    for line in file:\n",
    "\n",
    "        fields = line.split()\n",
    "        templist = []\n",
    "        features = len(fields)-1\n",
    "        for j in range(features):\n",
    "                #print(fields[j])\n",
    "            templist.append(float(fields[j]))\n",
    "\n",
    "        listx.append(templist)\n",
    "        listy.append(int(fields[features]))\n",
    "\n",
    "\n",
    "    if isTrainData:\n",
    "        samples = len(listx)\n",
    "        classes = len(set(listy))\n",
    "        \n",
    "    # convert into numpy array\n",
    "    x = np.array(listx)\n",
    "    y = np.array(listy)\n",
    "    x= (x - x.mean(axis = 0)) / x.std(axis = 0)\n",
    "    #print(x[:10])\n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x,train_y =  data_loader(\"trainNN.txt\",1)\n",
    "train_x = train_x.T\n",
    "train_y  = modify_y(classes,train_y).T\n",
    "print(\"Features: \",str(features), \" Classes: \",str(classes),\" Samples: \",str(samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_x,test_y =  data_loader(\"testNN.txt\",0)\n",
    "test_x = test_x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def derivative_sigmoid(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def error(target,output):\n",
    "    cost = np.sum((output - target) ** 2)\n",
    "    return cost / 2.0\n",
    "\n",
    "def derivative_error(target,output):\n",
    "    return target-output\n",
    "def softmax(x): \n",
    "    e_x = np.exp(x - np.max(x)) \n",
    "    return e_x / e_x.sum(axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,in_nodes,out_nodes):\n",
    "        np.random.seed(1)\n",
    "        self.weight = np.random.randn(out_nodes,in_nodes)\n",
    "        np.random.seed(0)\n",
    "        self.bias = np.random.randn(out_nodes,1)\n",
    "\n",
    "        self.Z = None\n",
    "        self.A = None\n",
    "\n",
    "        self.dZ = None\n",
    "        self.dA = None\n",
    "\n",
    "        self.prev_A = None\n",
    "\n",
    "    def forward(self,X):\n",
    "        self.prev_A = X.copy()\n",
    "\n",
    "        self.Z = np.matmul(self.weight,X)+self.bias\n",
    "        self.A = sigmoid(self.Z)\n",
    "        return self.A\n",
    "\n",
    "\n",
    "    def backward(self,delta,isLast ):\n",
    "\n",
    "        if isLast:\n",
    "            self.dA = self.A-delta.copy()\n",
    "        else:\n",
    "            self.dA = delta.copy()\n",
    "\n",
    "        self.dZ = self.dA * derivative_sigmoid(self.Z)\n",
    "\n",
    "        self.dW = np.matmul(self.dZ, self.prev_A.T)\n",
    "        self.db =  np.sum(self.dZ, axis=1, keepdims=True)\n",
    "\n",
    "        return np.matmul(self.weight.T, self.dA)\n",
    "\n",
    "    def update_weight(self,learning_rate):\n",
    "        self.weight = self.weight  - learning_rate * self.dW\n",
    "        self.bias = self.bias - learning_rate * self.db\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self,features, classes, size_layers):\n",
    "        self.layers = []\n",
    "\n",
    "        for i in range(1,len( size_layers)):\n",
    "            self.layers.append(Layer(size_layers[i-1],size_layers[i]))\n",
    "            #print(self.layers[-1].weight)\n",
    "        \n",
    "    def train(self,X,Y,epoch =1000, learning_rate = 0.1):\n",
    "        for i in range(epoch):\n",
    "            A = X\n",
    "            for layer in self.layers:\n",
    "                A = layer.forward(A)\n",
    "                #print(A)\n",
    "            \n",
    "            delta = Y\n",
    "            for layer in reversed(self.layers):\n",
    "                delta = layer.backward(delta, layer == self.layers[-1] )   \n",
    "\n",
    "            for layer in self.layers:\n",
    "                layer.update_weight(learning_rate)\n",
    "\n",
    "            # if((i+1)%100==0):\n",
    "            #     print('Iteration: ',str(i+1),' Error: ',error(self.layers[-1].A,Y))\n",
    "\n",
    "        # print('Train done!')\n",
    "\n",
    "    def decide(self, X):\n",
    "        A = X\n",
    "        for layer in self.layers:\n",
    "            A = layer.forward(A)\n",
    "\n",
    "        y_hat = []\n",
    "        for row in A.T:\n",
    "            # print(row)\n",
    "            # print(np.argmax(row) + 1)\n",
    "            y_hat.append(np.argmax(row) + 1)\n",
    "        #print(y_hat)\n",
    "        return np.asarray(y_hat)\n",
    "\n",
    "    def test(self,X,Y):\n",
    "        y_hat = self.decide(X)\n",
    "\n",
    "        #print(y_hat )\n",
    "        matches = np.count_nonzero(y_hat  == Y)\n",
    "        accuracy = matches / len(Y) * 100.0\n",
    "        #print(accuracy)\n",
    "        return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = set()\n",
    "for i in range (1,10):\n",
    "    for j in range(3,50):\n",
    "        np.random.seed(i*j)\n",
    "        layer_structure = [features]+np.random.randint(2,j,size=i).tolist()+[classes]\n",
    "        network = Network(features,classes, layer_structure)\n",
    "        network.train(train_x,train_y,2000,.01)\n",
    "        accuracy = network.test(test_x,test_y)\n",
    "        current_result = []\n",
    "        current_result.append(i)\n",
    "        current_result.append(layer_structure)\n",
    "        current_result.append(accuracy)\n",
    "        result.add(str(current_result))\n",
    "        print(str(i),layer_structure,str(accuracy))\n",
    "print('Final result:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in result:\n",
    "    print(res[1:len(res)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}