{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit ('deep-learning': conda)",
   "display_name": "Python 3.7.3 64-bit ('deep-learning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4efef21ae8d3e526766593316eddf58c065dc2704451dcdc2461b441e246bb8c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features=0\n",
    "classes=0\n",
    "samples=0\n",
    "def modify_y(classes,train_y):\n",
    "    new_train_y = []\n",
    "    for x in train_y:\n",
    "        current_y = []\n",
    "        for i in range(classes):\n",
    "            current_y.append(0)\n",
    "        current_y[int(x)-1]=1\n",
    "        new_train_y.append(current_y)\n",
    "    return np.array(new_train_y).T\n",
    "\n",
    "\n",
    "def data_loader(filename,isTrainData):\n",
    "    # open data file\n",
    "    file = open('./Dataset/'+filename,\"r\")\n",
    "\n",
    "\n",
    "    # initialize\n",
    "    i=0\n",
    "    global features\n",
    "    global classes\n",
    "    global samples\n",
    "\n",
    "\n",
    "    listx = []\n",
    "    listy = []\n",
    "\n",
    "    for line in file:\n",
    "\n",
    "        fields = line.split()\n",
    "        templist = []\n",
    "        features = len(fields)-1\n",
    "        for j in range(features):\n",
    "                #print(fields[j])\n",
    "            templist.append(float(fields[j]))\n",
    "\n",
    "        listx.append(templist)\n",
    "        listy.append(int(fields[features]))\n",
    "\n",
    "\n",
    "    if isTrainData:\n",
    "        samples = len(listx)\n",
    "        classes = len(set(listy))\n",
    "        \n",
    "    # convert into numpy array\n",
    "    x = np.array(listx)\n",
    "    y = np.array(listy)\n",
    "    max_value = np.max(x)\n",
    "    x/=max_value\n",
    "    #print(x.shape, y.shape)\n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x,train_y =  data_loader(\"trainNN.txt\",1)\n",
    "train_x = train_x.T\n",
    "train_y  = modify_y(classes,train_y)\n",
    "print(\"Features: \",str(features), \" Classes: \",str(classes),\" Samples: \",str(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x,test_y =  data_loader(\"testNN.txt\",0)\n",
    "test_x = test_x.T\n",
    "test_y  = modify_y(classes,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1.0/(1.0+np.exp(-z)))\n",
    "def derivative_sigmoid(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "def error(target,output):\n",
    "    return  np.sum((target-output)*(target-output))/2.0\n",
    "def derivative_error(target,output):\n",
    "    return target-output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,in_nodes,out_nodes):\n",
    "        self.weight = np.random.randn(out_nodes,in_nodes)\n",
    "        max_value = np.max(self.weight)\n",
    "        self.weight/=max_value\n",
    "\n",
    "        self.bias = np.random.randn(out_nodes,1)\n",
    "        max_value = np.max(self.bias)\n",
    "        self.bias/=max_value\n",
    "\n",
    "        self.Z = None\n",
    "        self.A = None\n",
    "\n",
    "        self.dZ = None\n",
    "        self.dA = None\n",
    "\n",
    "        self.prev_A = None\n",
    "\n",
    "    def forward(self,X):\n",
    "        self.prev_A = X\n",
    "\n",
    "        self.Z = np.dot(self.weight,X)+self.bias\n",
    "        self.A = sigmoid(self.Z)\n",
    "\n",
    "        return self.A\n",
    "\n",
    "\n",
    "    def backward(self,delta,isLast , m ,learning_rate):\n",
    "\n",
    "        if isLast:\n",
    "            self.dA = self.A-delta\n",
    "        else:\n",
    "            self.dA = delta\n",
    "\n",
    "        self.dZ = self.dA * derivative_sigmoid(self.A)\n",
    "\n",
    "        self.dW = np.dot(self.dZ, self.prev_A.T)*(1.0/m)\n",
    "        self.db =  np.sum(self.dZ, axis=1, keepdims=True)*(1.0/m)\n",
    "\n",
    "        self.weight = self.weight  - learning_rate * self.dW\n",
    "        self.bias = self.bias - learning_rate * self.db\n",
    "\n",
    "        return np.dot(self.weight.T, delta)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self,features, classes, size_layers):\n",
    "        self.layers = []\n",
    "\n",
    "        for i in range(1,len( size_layers)):\n",
    "            self.layers.append(Layer(size_layers[i-1],size_layers[i]))\n",
    "            # print(self.layers[-1].weight.shape)\n",
    "        \n",
    "    def train(self,X,Y,epoch =10000, learning_rate = 0.1):\n",
    "        for i in range(epoch):\n",
    "            A = X\n",
    "            for layer in self.layers:\n",
    "                A = layer.forward(A)\n",
    "            \n",
    "            delta = Y\n",
    "            for layer in reversed(self.layers):\n",
    "                delta = layer.backward(delta, layer == self.layers[-1] ,Y.shape[1],learning_rate)   \n",
    "\n",
    "            if((i+1)%100==0):\n",
    "                print('Iteration: ',str(i+1),' Error: ',error(self.layers[-1].A,Y))\n",
    "\n",
    "        print('Train done!')\n",
    "\n",
    "    def decide(self, X):\n",
    "        A = X\n",
    "        for layer in self.layers:\n",
    "            Z = np.dot(layer.weight,A)+layer.bias\n",
    "            A = sigmoid(Z)\n",
    "\n",
    "        y_temp = A.T.tolist() \n",
    "        #print(y_temp)\n",
    "        y_hat  = []\n",
    "        for row in y_temp:\n",
    "            y_hat.append(row.index(max(row)) + 1)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def test(self,X,Y):\n",
    "        m = Y.shape[1]\n",
    "\n",
    "        y_hat = self.decide(X)\n",
    "\n",
    "        n_miss = 0.0\n",
    "\n",
    "        Y = Y.T.tolist()\n",
    "        y  = []\n",
    "        for row in Y:\n",
    "            y.append(row.index(max(row)) + 1)\n",
    "\n",
    "        for i in range(m):\n",
    "            print('Expected: ',y[i],' Found: ',y_hat[i])\n",
    "            if (y[i] != y_hat[i]):\n",
    "                n_miss += 1\n",
    "\n",
    "        print(\"Test complete\\n\")\n",
    "\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        print(\"Total number of test samples = %d\" %(m))\n",
    "        print(\"Correctly classified         = %d\" %(m -n_miss))\n",
    "        print(\"Misclassified                = %d\" %(n_miss))\n",
    "\n",
    "        accuracy = float(m - n_miss) / float(m)\n",
    "        print(\"Accuracy                     = %f%%\" %(accuracy * 100))\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network = Network(features,classes, [features,8,classes])\n",
    "network.train(train_x,train_y)\n",
    "network.test(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}